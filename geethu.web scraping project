import requests
from bs4 import beautifulsoup
import pandas
import argparse
import connect
parser=argparse.argumentparser()
parser.add_argument("__page_num_max",help="enter the number of pages to parse",type_int)
parser.add_argument("__dbname",help="enter the number of pages to parse",type=int)
args=parser.parse_args()
oyo_url="https://www.oyorooms.com/hotels_in_bangalore/?page="
page_num_MAX=args.page_num_max
scraped_into_list=[]
connect.connect(args.dbname)
for page_num in range(1,page_num_MAX):
  req=requests.get(oyo_url+str(page_num))
  content=req.content
  soup=Beautifulsoup(content,"html.parser")
  all_hotels=soup.find_all("div",{"class":"hotelcardlisting"})
  for hotel in all_hotels:
  hotel_dict={}
  hotel_dict["name"]=hotel.find("h3",{"class":"listinghoteldescription_hotelname"}).text
  hotel_dict["address"]=hotel.find("span",{"itemprop":"streetaddress"}).text
  hotel_dict["price"]=hotel.find("span",{"class":"listingprice_finalprice}).text
  #try---except
  try:
    hotel_dict["rating"]=hotel.find("span",{"class="hotelrating_ratingsummary"}).text
  except attributeerror:
    pass
  parent_amenities_element=hotel.find{"div",{"class":"amentitywrapper"})
  amenities_list=[]
  for amenity in parent_amenities_element.find_all("div",{"class":"amenitywrapper_amenity"}):
    amenities_list.append(amenity.find("span",{"class":"d_body_sm"}).text.strip()}
  hotel_dict["amenities"]=','.join(amenities_list[:-1])
  scrapped_into_list.append(hotel_dict)
  connect.insert_into_table(args.dbname,tuple(hotel_dict.value())
  #print(hotel_name,hotel_address,hotel_price,price,hotel_rating,amenities_list)
 dataframe=pandas.dataframe(scraped_into_list)
 dataframe.to_csv("oyo.csv")
 connect.get_hotel_info(args.dbname)
